{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import models, transforms as T\nfrom PIL import Image\nimport numpy as np\nimport os\nimport matplotlib.pyplot as plt \n\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\nimsize = 256\nbeta = 1e5\n\nstyle_layers_names = ['conv1_1', 'conv2_1', 'conv3_1', 'conv4_1', 'conv5_1']\nstyle_weights = {'conv1_1': 1.0, 'conv2_1': 0.75, 'conv3_1': 0.2, 'conv4_1': 0.2, 'conv5_1': 0.2}\n\nlayer_name_to_index = {\n    'conv1_1': '0', 'conv2_1': '5', 'conv3_1': '10', 'conv4_1': '19', 'conv4_2': '21', 'conv5_1': '28'\n}\n\nstyle_layers_indices = {layer_name_to_index[name] for name in style_layers_names}\n\nlayers_for_inference = {idx: name for name, idx in layer_name_to_index.items() if idx in style_layers_indices}\n\n\n\nmodel = models.vgg19(weights=models.VGG19_Weights.DEFAULT).features.to(device).eval()\nfor param in model.parameters():\n    param.requires_grad_(False) \n    \ntry:\n    GRAMS_FILE_PATH = 'style_target_grams.pt' # Adjust this path\n    loaded_target_grams = torch.load(GRAMS_FILE_PATH, map_location=device)\n    print(f\"Style target grams loaded successfully from {GRAMS_FILE_PATH}.\")\nexcept FileNotFoundError:\n    print(f\"Error: {GRAMS_FILE_PATH} not found. Please ensure it's in the correct path.\")\n   \n    raise SystemExit(f\"Required file {GRAMS_FILE_PATH} not found.\")\nexcept Exception as e:\n    print(f\"Error loading style target grams: {e}\")\n    raise SystemExit(f\"Error loading style target grams: {e}\")\n\n\n\ndef image_loader(image: Image.Image, size=256, device=torch.device(\"cpu\")):\n    # VGG19 mean and std\n    normalize = T.Normalize(mean=[0.485, 0.456, 0.406],\n                            std=[0.229, 0.224, 0.225])\n    loader = T.Compose([\n        T.Resize(size),\n        T.CenterCrop(size), \n        T.ToTensor(),\n        normalize,\n    ])\n\n    image = image.convert('RGB') \n    image = loader(image).unsqueeze(0) # Add batch dimension\n    return image.to(device, torch.float)\n\ndef im_convert(tensor):\n    image = tensor.to(\"cpu\").clone().detach()\n    image = image.numpy().squeeze(0) \n    image = image.transpose(1, 2, 0) \n\n\n    image = np.clip(image, -2.5, 2.5) \n    image = image * np.array((0.229, 0.224, 0.225)) + np.array((0.485, 0.456, 0.406))\n\n    image = image.clip(0, 1)\n    return image\n\ndef gram_matrix(tensor):\n    b, c, h, w = tensor.size()\n    features = tensor.view(c, h * w) # Reshape features: (c, h*w)\n    gram = features.mm(features.t()) # Calculate gram matrix: features * features^T\n    return gram.div(c * h * w) # Normalize\n\ndef get_features(image, model, layers):\n    # Extracts features from specified layers of the model.\n    features = {}\n    x = image\n    i = 0\n    for module in model.children():\n        name = str(i)\n        x = module(x)\n        if name in layers:\n            features[layers[name]] = x\n        i += 1\n    return features\n\n\n\ndef stylize_image(content_image: Image.Image):\n    print(\"Starting style transfer inference...\")\n\n    try:\n        # 1. Load and preprocess the new content image\n        new_content_img = image_loader(content_image, size=imsize, device=device)\n\n        # 2. Initialize the generated image (clone of content)\n        generated_img = new_content_img.clone().requires_grad_(True).to(device)\n\n        # 3. Setup optimizer for the generated image\n        lr = 0.002\n        optimizer = optim.Adam([generated_img], lr=lr)\n\n        # 4. Run optimization loop\n        inference_steps = 100 # Number of optimization steps for inference\n        print(f\"Running {inference_steps} optimization steps...\")\n\n        for step in range(1, inference_steps + 1):\n            # Get features for the generated image\n            generated_features = get_features(generated_img, model, layers=layers_for_inference)\n\n            # Calculate style loss\n            current_style_loss = torch.tensor(0.0, device=device)\n            for layer_name in style_layers_names:\n                target_gram = loaded_target_grams[layer_name].to(device)\n                input_feature = generated_features[layer_name]\n                input_gram = gram_matrix(input_feature)\n                loss = nn.functional.mse_loss(input_gram, target_gram)\n                current_style_loss = current_style_loss + style_weights[layer_name] * loss\n\n            # Total loss (only style loss in inference mode)\n            total_loss = beta * current_style_loss\n\n            # Optimization step\n            optimizer.zero_grad()\n            total_loss.backward()\n            optimizer.step()\n\n            if step % 20 == 0: # Print every 20 steps\n                 print(f\"Step {step}/{inference_steps}, Loss: {total_loss.item():.4f}\")\n\n\n        print(\"Inference finished.\")\n\n        # 5. Convert the final tensor to a displayable image format\n        stylized_np_img = im_convert(generated_img)\n\n        return stylized_np_img\n\n    except Exception as e:\n        print(f\"An error occurred during style transfer: {e}\")\n        return None\n\n\nif __name__ == \"__main__\":\n    CONTENT_IMAGE_PATH = 'content.jpg' # Change to content image path\n\n    if not os.path.exists(CONTENT_IMAGE_PATH):\n        print(f\"Error: Content image not found at {CONTENT_IMAGE_PATH}\")\n        print(\"Please update CONTENT_IMAGE_PATH to point to a valid image file.\")\n    else:\n        try:\n            content_image = Image.open(CONTENT_IMAGE_PATH)\n            print(f\"Content image loaded successfully from {CONTENT_IMAGE_PATH}\")\n\n            # --- Run the style transfer ---\n            stylized_image_np = stylize_image(content_image)\n\n            # --- Display the result ---\n            if stylized_image_np is not None:\n                print(\"Displaying the stylized image:\")\n                plt.imshow(stylized_image_np)\n                plt.axis('off') # Hide axes\n                plt.title('Stylized Image')\n                plt.show()\n            else:\n                print(\"Style transfer failed.\")\n\n        except Exception as e:\n            print(f\"An error occurred during image loading or display: {e}\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null}]}
